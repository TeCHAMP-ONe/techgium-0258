{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r_D-RR8BsvaE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zCMlYiFtEW5",
        "outputId": "63ef33c9-de4f-40e7-d5ab-61d1f6f6a298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-03 07:17:51--  https://huggingface.co/datasets/geekyrakshit/LoL-Dataset/resolve/main/lol_dataset.zip\n",
            "Resolving huggingface.co (huggingface.co)... 65.8.178.12, 65.8.178.118, 65.8.178.27, ...\n",
            "Connecting to huggingface.co (huggingface.co)|65.8.178.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/d9/09/d909ef7668bb417b7065a311bd55a3084cc83a1f918e13cb41c5503328432db2/419fddc48958cd0f5599939ee0248852a37ceb8bb738c9b9525e95b25a89de9a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27lol_dataset.zip%3B+filename%3D%22lol_dataset.zip%22%3B&response-content-type=application%2Fzip&Expires=1709709472&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTcwOTQ3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9kOS8wOS9kOTA5ZWY3NjY4YmI0MTdiNzA2NWEzMTFiZDU1YTMwODRjYzgzYTFmOTE4ZTEzY2I0MWM1NTAzMzI4NDMyZGIyLzQxOWZkZGM0ODk1OGNkMGY1NTk5OTM5ZWUwMjQ4ODUyYTM3Y2ViOGJiNzM4YzliOTUyNWU5NWIyNWE4OWRlOWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=eKCH1fHHHcCSMtmNgoSuFK3%7EOIO9N%7EuW6JHeCSm2ln-Gn-hwyIFLbdE05g9Ux-skNmASY5cV%7E9%7E3tshHmjsNXYNyl3BdQYHr-9wqZ7wJ-HvMCzOCeZlAKnnqoX4jPH8dW3U4oHxQzt4aGiLMUaMi1KqxSSrVFG5ddhBTDBQEjnMDgIKQeu7PeEhbasBKAdMPwsVipsioXRUBeWwKqRjSBCVLM3RCNa3YyJP9CVWFEJnHb7gt5gITNwM2ophLt2PQc2TKeLUtwThba9Vz3TAV8STu3NTD4R9eLm86pPy8kso4FgSVTifOPmJLf8-lHYs0Z%7E2Fe%7Ec8lCo7x4ccBrs45w__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-03-03 07:17:52--  https://cdn-lfs.huggingface.co/repos/d9/09/d909ef7668bb417b7065a311bd55a3084cc83a1f918e13cb41c5503328432db2/419fddc48958cd0f5599939ee0248852a37ceb8bb738c9b9525e95b25a89de9a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27lol_dataset.zip%3B+filename%3D%22lol_dataset.zip%22%3B&response-content-type=application%2Fzip&Expires=1709709472&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTcwOTQ3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9kOS8wOS9kOTA5ZWY3NjY4YmI0MTdiNzA2NWEzMTFiZDU1YTMwODRjYzgzYTFmOTE4ZTEzY2I0MWM1NTAzMzI4NDMyZGIyLzQxOWZkZGM0ODk1OGNkMGY1NTk5OTM5ZWUwMjQ4ODUyYTM3Y2ViOGJiNzM4YzliOTUyNWU5NWIyNWE4OWRlOWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=eKCH1fHHHcCSMtmNgoSuFK3%7EOIO9N%7EuW6JHeCSm2ln-Gn-hwyIFLbdE05g9Ux-skNmASY5cV%7E9%7E3tshHmjsNXYNyl3BdQYHr-9wqZ7wJ-HvMCzOCeZlAKnnqoX4jPH8dW3U4oHxQzt4aGiLMUaMi1KqxSSrVFG5ddhBTDBQEjnMDgIKQeu7PeEhbasBKAdMPwsVipsioXRUBeWwKqRjSBCVLM3RCNa3YyJP9CVWFEJnHb7gt5gITNwM2ophLt2PQc2TKeLUtwThba9Vz3TAV8STu3NTD4R9eLm86pPy8kso4FgSVTifOPmJLf8-lHYs0Z%7E2Fe%7Ec8lCo7x4ccBrs45w__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 99.84.252.48, 99.84.252.27, 99.84.252.42, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|99.84.252.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347171015 (331M) [application/zip]\n",
            "Saving to: ‘lol_dataset.zip’\n",
            "\n",
            "lol_dataset.zip     100%[===================>] 331.09M  38.3MB/s    in 8.8s    \n",
            "\n",
            "2024-03-03 07:18:01 (37.7 MB/s) - ‘lol_dataset.zip’ saved [347171015/347171015]\n",
            "\n",
            "replace lol_dataset/eval15/high/748.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/geekyrakshit/LoL-Dataset/resolve/main/lol_dataset.zip\n",
        "!unzip -q lol_dataset.zip && rm lol_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrjS4T4CtRrd"
      },
      "outputs": [],
      "source": [
        "random.seed(10)\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 4\n",
        "MAX_TRAIN_IMAGES = 300\n",
        "\n",
        "\n",
        "def read_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "    image = tf.cast(image, dtype=tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_crop(low_image, enhanced_image):\n",
        "    low_image_shape = tf.shape(low_image)[:2]\n",
        "    low_w = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[1] - IMAGE_SIZE + 1, dtype=tf.int32\n",
        "    )\n",
        "    low_h = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[0] - IMAGE_SIZE + 1, dtype=tf.int32\n",
        "    )\n",
        "    low_image_cropped = low_image[\n",
        "        low_h : low_h + IMAGE_SIZE, low_w : low_w + IMAGE_SIZE\n",
        "    ]\n",
        "    enhanced_image_cropped = enhanced_image[\n",
        "        low_h : low_h + IMAGE_SIZE, low_w : low_w + IMAGE_SIZE\n",
        "    ]\n",
        "    # in order to avoid `NONE` during shape inference\n",
        "    low_image_cropped.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
        "    enhanced_image_cropped.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
        "    return low_image_cropped, enhanced_image_cropped\n",
        "\n",
        "\n",
        "def load_data(low_light_image_path, enhanced_image_path):\n",
        "    low_light_image = read_image(low_light_image_path)\n",
        "    enhanced_image = read_image(enhanced_image_path)\n",
        "    low_light_image, enhanced_image = random_crop(low_light_image, enhanced_image)\n",
        "    return low_light_image, enhanced_image\n",
        "\n",
        "\n",
        "def get_dataset(low_light_images, enhanced_images):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images, enhanced_images))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n",
        "train_enhanced_images = sorted(glob(\"./lol_dataset/our485/high/*\"))[:MAX_TRAIN_IMAGES]\n",
        "\n",
        "val_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n",
        "val_enhanced_images = sorted(glob(\"./lol_dataset/our485/high/*\"))[MAX_TRAIN_IMAGES:]\n",
        "\n",
        "test_low_light_images = sorted(glob(\"./lol_dataset/eval15/low/*\"))\n",
        "test_enhanced_images = sorted(glob(\"./lol_dataset/eval15/high/*\"))\n",
        "\n",
        "\n",
        "train_dataset = get_dataset(train_low_light_images, train_enhanced_images)\n",
        "val_dataset = get_dataset(val_low_light_images, val_enhanced_images)\n",
        "\n",
        "\n",
        "print(\"Train Dataset:\", train_dataset.element_spec)\n",
        "print(\"Val Dataset:\", val_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SKirZrjtpRR"
      },
      "outputs": [],
      "source": [
        "def selective_kernel_feature_fusion(\n",
        "    multi_scale_feature_1, multi_scale_feature_2, multi_scale_feature_3\n",
        "):\n",
        "    channels = list(multi_scale_feature_1.shape)[-1]\n",
        "    combined_feature = layers.Add()(\n",
        "        [multi_scale_feature_1, multi_scale_feature_2, multi_scale_feature_3]\n",
        "    )\n",
        "    gap = layers.GlobalAveragePooling2D()(combined_feature)\n",
        "    channel_wise_statistics = layers.Reshape((1, 1, channels))(gap)\n",
        "    compact_feature_representation = layers.Conv2D(\n",
        "        filters=channels // 8, kernel_size=(1, 1), activation=\"relu\"\n",
        "    )(channel_wise_statistics)\n",
        "    feature_descriptor_1 = layers.Conv2D(\n",
        "        channels, kernel_size=(1, 1), activation=\"softmax\"\n",
        "    )(compact_feature_representation)\n",
        "    feature_descriptor_2 = layers.Conv2D(\n",
        "        channels, kernel_size=(1, 1), activation=\"softmax\"\n",
        "    )(compact_feature_representation)\n",
        "    feature_descriptor_3 = layers.Conv2D(\n",
        "        channels, kernel_size=(1, 1), activation=\"softmax\"\n",
        "    )(compact_feature_representation)\n",
        "    feature_1 = multi_scale_feature_1 * feature_descriptor_1\n",
        "    feature_2 = multi_scale_feature_2 * feature_descriptor_2\n",
        "    feature_3 = multi_scale_feature_3 * feature_descriptor_3\n",
        "    aggregated_feature = layers.Add()([feature_1, feature_2, feature_3])\n",
        "    return aggregated_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UtrGGw5twV9"
      },
      "outputs": [],
      "source": [
        "class ChannelPooling(layers.Layer):\n",
        "    def __init__(self, axis=-1, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.axis = axis\n",
        "        self.concat = layers.Concatenate(axis=self.axis)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        average_pooling = tf.expand_dims(tf.reduce_mean(inputs, axis=-1), axis=-1)\n",
        "        max_pooling = tf.expand_dims(tf.reduce_max(inputs, axis=-1), axis=-1)\n",
        "        return self.concat([average_pooling, max_pooling])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"axis\": self.axis})\n",
        "\n",
        "\n",
        "def spatial_attention_block(input_tensor):\n",
        "    compressed_feature_map = ChannelPooling(axis=-1)(input_tensor)\n",
        "    feature_map = layers.Conv2D(1, kernel_size=(1, 1))(compressed_feature_map)\n",
        "    feature_map = keras.activations.sigmoid(feature_map)\n",
        "    return input_tensor * feature_map\n",
        "\n",
        "\n",
        "def channel_attention_block(input_tensor):\n",
        "    channels = list(input_tensor.shape)[-1]\n",
        "    average_pooling = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    feature_descriptor = layers.Reshape((1, 1, channels))(average_pooling)\n",
        "    feature_activations = layers.Conv2D(\n",
        "        filters=channels // 8, kernel_size=(1, 1), activation=\"relu\"\n",
        "    )(feature_descriptor)\n",
        "    feature_activations = layers.Conv2D(\n",
        "        filters=channels, kernel_size=(1, 1), activation=\"sigmoid\"\n",
        "    )(feature_activations)\n",
        "    return input_tensor * feature_activations\n",
        "\n",
        "\n",
        "def dual_attention_unit_block(input_tensor):\n",
        "    channels = list(input_tensor.shape)[-1]\n",
        "    feature_map = layers.Conv2D(\n",
        "        channels, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
        "    )(input_tensor)\n",
        "    feature_map = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(\n",
        "        feature_map\n",
        "    )\n",
        "    channel_attention = channel_attention_block(feature_map)\n",
        "    spatial_attention = spatial_attention_block(feature_map)\n",
        "    concatenation = layers.Concatenate(axis=-1)([channel_attention, spatial_attention])\n",
        "    concatenation = layers.Conv2D(channels, kernel_size=(1, 1))(concatenation)\n",
        "    return layers.Add()([input_tensor, concatenation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzMM-RAztzu-"
      },
      "outputs": [],
      "source": [
        "# Recursive Residual Modules\n",
        "\n",
        "\n",
        "def down_sampling_module(input_tensor):\n",
        "    channels = list(input_tensor.shape)[-1]\n",
        "    main_branch = layers.Conv2D(channels, kernel_size=(1, 1), activation=\"relu\")(\n",
        "        input_tensor\n",
        "    )\n",
        "    main_branch = layers.Conv2D(\n",
        "        channels, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
        "    )(main_branch)\n",
        "    main_branch = layers.MaxPooling2D()(main_branch)\n",
        "    main_branch = layers.Conv2D(channels * 2, kernel_size=(1, 1))(main_branch)\n",
        "    skip_branch = layers.MaxPooling2D()(input_tensor)\n",
        "    skip_branch = layers.Conv2D(channels * 2, kernel_size=(1, 1))(skip_branch)\n",
        "    return layers.Add()([skip_branch, main_branch])\n",
        "\n",
        "\n",
        "def up_sampling_module(input_tensor):\n",
        "    channels = list(input_tensor.shape)[-1]\n",
        "    main_branch = layers.Conv2D(channels, kernel_size=(1, 1), activation=\"relu\")(\n",
        "        input_tensor\n",
        "    )\n",
        "    main_branch = layers.Conv2D(\n",
        "        channels, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
        "    )(main_branch)\n",
        "    main_branch = layers.UpSampling2D()(main_branch)\n",
        "    main_branch = layers.Conv2D(channels // 2, kernel_size=(1, 1))(main_branch)\n",
        "    skip_branch = layers.UpSampling2D()(input_tensor)\n",
        "    skip_branch = layers.Conv2D(channels // 2, kernel_size=(1, 1))(skip_branch)\n",
        "    return layers.Add()([skip_branch, main_branch])\n",
        "\n",
        "\n",
        "# MRB Block\n",
        "def multi_scale_residual_block(input_tensor, channels):\n",
        "    # features\n",
        "    level1 = input_tensor\n",
        "    level2 = down_sampling_module(input_tensor)\n",
        "    level3 = down_sampling_module(level2)\n",
        "    # DAU\n",
        "    level1_dau = dual_attention_unit_block(level1)\n",
        "    level2_dau = dual_attention_unit_block(level2)\n",
        "    level3_dau = dual_attention_unit_block(level3)\n",
        "    # SKFF\n",
        "    level1_skff = selective_kernel_feature_fusion(\n",
        "        level1_dau,\n",
        "        up_sampling_module(level2_dau),\n",
        "        up_sampling_module(up_sampling_module(level3_dau)),\n",
        "    )\n",
        "    level2_skff = selective_kernel_feature_fusion(\n",
        "        down_sampling_module(level1_dau),\n",
        "        level2_dau,\n",
        "        up_sampling_module(level3_dau),\n",
        "    )\n",
        "    level3_skff = selective_kernel_feature_fusion(\n",
        "        down_sampling_module(down_sampling_module(level1_dau)),\n",
        "        down_sampling_module(level2_dau),\n",
        "        level3_dau,\n",
        "    )\n",
        "    # DAU 2\n",
        "    level1_dau_2 = dual_attention_unit_block(level1_skff)\n",
        "    level2_dau_2 = up_sampling_module((dual_attention_unit_block(level2_skff)))\n",
        "    level3_dau_2 = up_sampling_module(\n",
        "        up_sampling_module(dual_attention_unit_block(level3_skff))\n",
        "    )\n",
        "    # SKFF 2\n",
        "    skff_ = selective_kernel_feature_fusion(level1_dau_2, level2_dau_2, level3_dau_2)\n",
        "    conv = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(skff_)\n",
        "    return layers.Add()([input_tensor, conv])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAsfHDUkt3Wm"
      },
      "outputs": [],
      "source": [
        "def recursive_residual_group(input_tensor, num_mrb, channels):\n",
        "    conv1 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(input_tensor)\n",
        "    for _ in range(num_mrb):\n",
        "        conv1 = multi_scale_residual_block(conv1, channels)\n",
        "    conv2 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(conv1)\n",
        "    return layers.Add()([conv2, input_tensor])\n",
        "\n",
        "\n",
        "def mirnet_model(num_rrg, num_mrb, channels):\n",
        "    input_tensor = keras.Input(shape=[None, None, 3])\n",
        "    x1 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(input_tensor)\n",
        "    for _ in range(num_rrg):\n",
        "        x1 = recursive_residual_group(x1, num_mrb, channels)\n",
        "    conv = layers.Conv2D(3, kernel_size=(3, 3), padding=\"same\")(x1)\n",
        "    output_tensor = layers.Add()([input_tensor, conv])\n",
        "    return keras.Model(input_tensor, output_tensor)\n",
        "\n",
        "\n",
        "model = mirnet_model(num_rrg=3, num_mrb=2, channels=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "p5Ha7P1Rt6NR",
        "outputId": "f31a848b-bdd3-45ba-962c-f55f8d449da9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-05c5fe6598c5>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"peak_signal_noise_ratio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PSNR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-05c5fe6598c5>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(value, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"train_{name.lower()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"val_{value}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"val_{name.lower()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "def charbonnier_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.sqrt(tf.square(y_true - y_pred) + tf.square(1e-3)))\n",
        "\n",
        "\n",
        "def peak_signal_noise_ratio(y_true, y_pred):\n",
        "    return tf.image.psnr(y_pred, y_true, max_val=255.0)\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=charbonnier_loss,\n",
        "    metrics=[peak_signal_noise_ratio],\n",
        ")\n",
        "\n",
        "# history = model.fit(\n",
        "#     train_dataset,\n",
        "#     validation_data=val_dataset,\n",
        "#     epochs=50,\n",
        "#     callbacks=[\n",
        "#         keras.callbacks.ReduceLROnPlateau(\n",
        "#             monitor=\"val_peak_signal_noise_ratio\",\n",
        "#             factor=0.5,\n",
        "#             patience=5,\n",
        "#             verbose=1,\n",
        "#             min_delta=1e-7,\n",
        "#             mode=\"max\",\n",
        "#         )\n",
        "#     ],\n",
        "# )\n",
        "\n",
        "\n",
        "# def plot_history(value, name):\n",
        "#     plt.plot(history.history[value], label=f\"train_{name.lower()}\")\n",
        "#     plt.plot(history.history[f\"val_{value}\"], label=f\"val_{name.lower()}\")\n",
        "#     plt.xlabel(\"Epochs\")\n",
        "#     plt.ylabel(name)\n",
        "#     plt.title(f\"Train and Validation {name} Over Epochs\", fontsize=14)\n",
        "#     plt.legend()\n",
        "#     plt.grid()\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# plot_history(\"loss\", \"Loss\")\n",
        "# plot_history(\"peak_signal_noise_ratio\", \"PSNR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Znc9910iCm3m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, optimizers, callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Your model training code goes here\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        callbacks.ReduceLROnPlateau(\n",
        "            monitor=\"val_peak_signal_noise_ratio\",\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "            min_delta=1e-7,\n",
        "            mode=\"max\",\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Save the trained model as HDF5 file\n",
        "model.save(\"mirnet_model.h5\")\n",
        "\n",
        "# Load the model from the saved HDF5 file\n",
        "loaded_model = models.load_model(\"mirnet_model.h5\")\n",
        "\n",
        "# Serialize and save the loaded model as a pickle file\n",
        "with open(\"mirnet_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(loaded_model, f)\n",
        "\n",
        "# Load the model from the pickle file\n",
        "with open(\"mirnet_model.pkl\", \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "# Function to preprocess input image and get enhanced image\n",
        "def enhance_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.cast(image, dtype=tf.float32) / 255.0\n",
        "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    enhanced_image = loaded_model.predict(image)\n",
        "    enhanced_image = np.squeeze(enhanced_image, axis=0)  # Remove batch dimension\n",
        "    enhanced_image = np.clip(enhanced_image * 255.0, 0, 255).astype(np.uint8)\n",
        "    return enhanced_image\n",
        "\n",
        "# Example usage:\n",
        "input_image_path = \"input_image.png\"\n",
        "enhanced_image = enhance_image(input_image_path)\n",
        "plt.imshow(enhanced_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpFSofiDIPl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}